# Orquestaci칩n de flujos de datos

## De ETL a ELT con Google Cloud

* V칤deo original (en ingl칠s): [ETL vs ELT](https://www.youtube.com/watch?v=E04yurp1tSU)

En esta sesi칩n vamos a implementar un proceso similar al que implementamos en cap칤tulos anteriores, solo que con un cambio de arquitectura en nuestro flujo.

Hasta ahora, nuestro flujo segu칤a un esquema ETL:

* **Extracci칩n**: descarga de los ficheros de datos y decompresi칩n para obtener los CSV guardando sus datos en una tabla de "staging",
* **Transformaci칩n**: adici칩n de una clave 칰nica y de una columna que permita identificar el fichero del que viene cada registro,
* **Carga**: inserci칩n en una tabla "final" de nuestro servidor PostgreSQL local.

> [!NOTE]
> ETL son las siglas, en ingl칠s, correspondientes a **E**xtract, **T**ransform y **L**oad.

En esta sesi칩n optaremos por un esquema ELT, en el que el orden de los pasos cambia:

* **Extracci칩n**: descarga de los ficheros de datos y decompresi칩n para obtener los CSV guard치ndolos esta vez sin transformar,
* **Carga**: en Google Cloud Buckets (que ser치 nuestro _lago de datos_) sin modificar los ficheros,
* **Transformaci칩n** transformaci칩n de datos "al vuelo" usando BigQuery.

Gracias a este enfoque:

* Mantendremos los costes controlados, porque los datos descargados sin modificar estar치n en nuestro _lago de datos_ (una forma econ칩mica de almacenamiento en la nube).
* Podremos decidir a posteriori qu칠 transformaciones realizar, de forma que ser치 m치s sencillo realizar distintos an치lisis sobre los datos.

## Configurar Google Cloud y BigQuery

* V칤deo original (en ingl칠s): [Setting up Google Cloud and BigQuery](https://www.youtube.com/watch?v=TLGFAOHpOYM&pp=ugUEEgJlbg%3D%3D)

### Credenciales

Asumiendo que ya tenemos una cuenta en Google Cloud, necesitaremos descargarnos las credenciales (en formato JSON) de una cuenta con acceso al proyecto en el que estaremos trabajando. Una vez tengamos el fichero, podremos ir al directorio en el que tenemos nuestro [docker-compose.yml](pipeline/docker-compose.yml) y a침adir las credenciales a nuestras variables de entorno con:

```bash
# Asumiendo que nuestras credenciales est치n en `service-account.json`
echo SECRET_GCP_SERVICE_ACCOUNT=$(cat service-account.json | base64 -w 0) >> .env
```

Tambi칠n tendremos que asegurarnos de hacer `SERVICE_GCP_SERVICE_ACCOUNT` accesible como variable de entorno desde nuestro contenedor **kestra**. Una manera de conseguirlo es mediante la clave **environment** de nuestro servicio:

```yaml
kestra:
  environment:
    SECRET_GCP_SERVICE_ACCOUNT: ${SECRET_GCP_SERVICE_ACCOUNT}
```

### Otras variables

Para hacer referencia a otras variables sobre nuestra cuenta Google Cloud, definiremos cuatro pares de clave y valor:

| **Clave** | **Valor** (ejemplo) |
| --- | --- |
| GCP_BUCKET_NAME | newyork-taxi |
| GCP_DATASET | zoomcamp |
| GCP_LOCATION | europe-west1 |
| GCP_PROJECT_ID | zoomcamp-ingenieria-datos |

Para agilizar esta tarea, puedes usar un flujo que crea por ti estos pares de clave y valor: [06-gcp-key-value-pairs](resources/flows/06-gcp-key-value-pairs).

### Creaci칩n de recursos desde Kestra

Aunque podemos crear nuestro **bucket** de Cloud Storage y nuestro **dataset** de BigQuery a mano, Kestra dispone de tareas que nos pueden facilitar la gesti칩n:

```yaml
id: 07_gcp_setup
namespace: zoomcamp

tasks:
  - id: create_gcs_bucket
    type: io.kestra.plugin.gcp.gcs.CreateBucket
    ifExists: SKIP
    storageClass: REGIONAL
    name: "{{ kv('GCP_BUCKET_NAME') }}"

  - id: create_bq_dataset
    type: io.kestra.plugin.gcp.bigquery.CreateDataset
    name: "{{ kv('GCP_DATASET') }}"
    ifExists: SKIP

pluginDefaults:
  - type: io.kestra.plugin.gcp
    values:
      serviceAccount: "{{ secret('GCP_SERVICE_ACCOUNT') }}"
      projectId: "{{ kv('GCP_PROJECT_ID') }}"
      location: "{{ kv('GCP_LOCATION') }}"
      bucket: "{{ kv('GCP_BUCKET_NAME') }}"
```

## Carga de datos

* V칤deo original (en ingl칠s): [Load Data into BigQuery](https://www.youtube.com/watch?v=52u9X_bfTAo)

Por fin, vamos a crear una versi칩n de nuestro flujo de datos que aproveche las ventajas del trabajo en la nube con un esquema ELT. Para empezar, vamos a crear un flujo que pida los datos del _dataset_, a침o y mes a procesar. M치s adelante, lo ampliaremos para poder programarlo y lanzar rellenos de datos hist칩ricos como hicimos en la sesi칩n anterior.

### Entradas

En cuanto a las entradas de datos que usaremos, ser치n similares a las que ya definimos cuando implementamos [nuestra versi칩n ETL del flujo](06-datos-del-dataset-de-taxis-de-nueva-york.md):

```yaml
inputs:
  - id: taxi
    type: SELECT
    displayName: Select taxi type
    values: [yellow, green]
    defaults: green

  - id: year
    type: SELECT
    displayName: Select year
    values: ["2019", "2020"]
    defaults: "2019"
    allowCustomValue: true # allows you to type 2021 from the UI for the homework 游뱅

  - id: month
    type: SELECT
    displayName: Select month
    values: ["01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12"]
    defaults: "01"
```

### Variables

En cuanto a las variables, esta vez nos ser치 칰til poder referirnos al bucket, por lo que definiremos una nueva variable **gcs_file**:

```yaml
variables:
  source: "https://github.com/DataTalksClub/nyc-tlc-data/releases/download"
  file: "{{ inputs.taxi }}_tripdata_{{ inputs.year }}-{{ inputs.month }}.csv"
  gcs_file: "gs://{{ kv('GCP_BUCKET_NAME') }}/{{ vars.file }}"
  table: "{{ kv('GCP_DATASET') }}.{{ inputs.taxi }}_tripdata_{{ inputs.year }}_{{ inputs.month }}"
  data: "{{ outputs.extract.outputFiles[inputs.taxi ~ '_tripdata_' ~ inputs.year ~ '-' ~ inputs.month ~ '.csv'] }}"
```

### Tareas

#### Etiquetas

La primera tarea de nuestro nuevo flujo ser치 id칠ntica a la que ya usamos en nuestros flujos anteriores. Su prop칩sito ser치 etiquetar las ejecuciones para facilitar su control.

```yaml
tasks:
  - id: set_label
    type: io.kestra.plugin.core.execution.Labels
    labels:
      file: "{{ render(vars.file) }}"
      taxi: "{{ inputs.taxi }}"
```

#### Extracci칩n

La segunda tarea tambi칠n ser치 similar a la que usamos en versiones anteriores del flujo para descargar y descomprimir los ficheros.

```yaml
- id: extract
  type: io.kestra.plugin.scripts.shell.Commands
  outputFiles:
    - "*.csv"
  taskRunner:
  type: io.kestra.plugin.core.runner.Process
  commands:
    - wget -qO- {{ vars.source }}/{{ inputs.taxi }}/{{ render(vars.file) }}.gz | gunzip > {{ render(vars.file) }}
```

#### Subida de ficheros al **bucket**

La primera diferencia se encontrar치 en nuestra tercera tarea. En este caso, a침adiremos una tarea cuyo cometido ser치 subir los ficheros descargados a nuestro _lago de datos_ en Google Cloud.

```yaml
- id: upload_to_gcs
  type: io.kestra.plugin.gcp.gcs.Upload
  from: "{{ render(vars.data) }}"
  to: "{{ render(vars.gcs_file) }}"
```

Como esta y la mayor칤a de las tareas de conformar치n este flujo compartir치n datos de conexi칩n, hemos decidido extraerlos a una secci칩n de valores por defecto de plugins.

```yaml
pluginDefaults:
  - type: io.kestra.plugin.gcp
    values:
      serviceAccount: "{{ secret('GCP_SERVICE_ACCOUNT') }}"
      projectId: "{{ kv('GCP_PROJECT_ID') }}"
      location: "{{ kv('GCP_LOCATION') }}"
      bucket: "{{ kv('GCP_BUCKET_NAME') }}"
```

#### Ramificaci칩n por **dataset**

A continuaci칩n, nuestro flujo se abrir치 en dos ramas diferentes, una para cada conjunto de datos: el de datos de taxis amarillos y el de datos de taxis verdes. Como ambas ramas son muy parecidas, en este documento nos centraremos en la taxis amarillos. De la ramificaci칩n se encargar치 una tarea de tipo flujo:

```yaml
- id: if_yellow_taxi
  type: io.kestra.plugin.core.flow.If
  condition: "{{inputs.taxi == 'yellow'}}"
  then:
    # Tareas que solo se ejecutar치n para datasets de taxis amarillos
```

##### Creaci칩n de la tabla "final"

Lo primero que haremos para gestionar los datos de taxis amarillos ser치 a crear, si no existe a칰n, la tabla "final" que alojar치 los datos en BigQuery.

```sql
CREATE TABLE IF NOT EXISTS `{{ kv('GCP_PROJECT_ID') }}.{{ kv('GCP_DATASET') }}.yellow_tripdata`
(
    unique_row_id BYTES OPTIONS (description = 'A unique identifier for the trip, generated by hashing key trip attributes.'),
    filename STRING OPTIONS (description = 'The source filename from which the trip data was loaded.'),      
    VendorID STRING OPTIONS (description = 'A code indicating the LPEP provider that provided the record. 1= Creative Mobile Technologies, LLC; 2= VeriFone Inc.'),
    tpep_pickup_datetime TIMESTAMP OPTIONS (description = 'The date and time when the meter was engaged'),
    tpep_dropoff_datetime TIMESTAMP OPTIONS (description = 'The date and time when the meter was disengaged'),
    passenger_count INTEGER OPTIONS (description = 'The number of passengers in the vehicle. This is a driver-entered value.'),
    trip_distance NUMERIC OPTIONS (description = 'The elapsed trip distance in miles reported by the taximeter.'),
    RatecodeID STRING OPTIONS (description = 'The final rate code in effect at the end of the trip. 1= Standard rate 2=JFK 3=Newark 4=Nassau or Westchester 5=Negotiated fare 6=Group ride'),
    store_and_fwd_flag STRING OPTIONS (description = 'This flag indicates whether the trip record was held in vehicle memory before sending to the vendor, aka "store and forward," because the vehicle did not have a connection to the server. TRUE = store and forward trip, FALSE = not a store and forward trip'),
    PULocationID STRING OPTIONS (description = 'TLC Taxi Zone in which the taximeter was engaged'),
    DOLocationID STRING OPTIONS (description = 'TLC Taxi Zone in which the taximeter was disengaged'),
    payment_type INTEGER OPTIONS (description = 'A numeric code signifying how the passenger paid for the trip. 1= Credit card 2= Cash 3= No charge 4= Dispute 5= Unknown 6= Voided trip'),
    fare_amount NUMERIC OPTIONS (description = 'The time-and-distance fare calculated by the meter'),
    extra NUMERIC OPTIONS (description = 'Miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges'),
    mta_tax NUMERIC OPTIONS (description = '$0.50 MTA tax that is automatically triggered based on the metered rate in use'),
    tip_amount NUMERIC OPTIONS (description = 'Tip amount. This field is automatically populated for credit card tips. Cash tips are not included.'),
    tolls_amount NUMERIC OPTIONS (description = 'Total amount of all tolls paid in trip.'),
    improvement_surcharge NUMERIC OPTIONS (description = '$0.30 improvement surcharge assessed on hailed trips at the flag drop. The improvement surcharge began being levied in 2015.'),
    total_amount NUMERIC OPTIONS (description = 'The total amount charged to passengers. Does not include cash tips.'),
    congestion_surcharge NUMERIC OPTIONS (description = 'Congestion surcharge applied to trips in congested zones')
)
PARTITION BY DATE(tpep_pickup_datetime);
```

La consulta de creaci칩n de la tabla la ejecutaremos con una tarea de tipo _consulta de BigQuery_.

```yaml
- id: bq_yellow_tripdata
  type: io.kestra.plugin.gcp.bigquery.Query
  sql: |
    # Creaci칩n de la tabla "final"
```

##### Creaci칩n de las tablas "externas"

La gran novedad de nuestro proceso ELT viene aqu칤: crearemos una tabla que no contiene datos. En su lugar, es una tabla "externa", que apunta a los datos contenidos por el fichero CSV que acabamos de subir a nuestro bucket.

```sql
CREATE OR REPLACE EXTERNAL TABLE `{{ kv('GCP_PROJECT_ID') }}.{{ render(vars.table) }}_ext`
(
    VendorID STRING OPTIONS (description = 'A code indicating the LPEP provider that provided the record. 1= Creative Mobile Technologies, LLC; 2= VeriFone Inc.'),
    tpep_pickup_datetime TIMESTAMP OPTIONS (description = 'The date and time when the meter was engaged'),
    tpep_dropoff_datetime TIMESTAMP OPTIONS (description = 'The date and time when the meter was disengaged'),
    passenger_count INTEGER OPTIONS (description = 'The number of passengers in the vehicle. This is a driver-entered value.'),
    trip_distance NUMERIC OPTIONS (description = 'The elapsed trip distance in miles reported by the taximeter.'),
    RatecodeID STRING OPTIONS (description = 'The final rate code in effect at the end of the trip. 1= Standard rate 2=JFK 3=Newark 4=Nassau or Westchester 5=Negotiated fare 6=Group ride'),
    store_and_fwd_flag STRING OPTIONS (description = 'This flag indicates whether the trip record was held in vehicle memory before sending to the vendor, aka "store and forward," because the vehicle did not have a connection to the server. TRUE = store and forward trip, FALSE = not a store and forward trip'),
    PULocationID STRING OPTIONS (description = 'TLC Taxi Zone in which the taximeter was engaged'),
    DOLocationID STRING OPTIONS (description = 'TLC Taxi Zone in which the taximeter was disengaged'),
    payment_type INTEGER OPTIONS (description = 'A numeric code signifying how the passenger paid for the trip. 1= Credit card 2= Cash 3= No charge 4= Dispute 5= Unknown 6= Voided trip'),
    fare_amount NUMERIC OPTIONS (description = 'The time-and-distance fare calculated by the meter'),
    extra NUMERIC OPTIONS (description = 'Miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges'),
    mta_tax NUMERIC OPTIONS (description = '$0.50 MTA tax that is automatically triggered based on the metered rate in use'),
    tip_amount NUMERIC OPTIONS (description = 'Tip amount. This field is automatically populated for credit card tips. Cash tips are not included.'),
    tolls_amount NUMERIC OPTIONS (description = 'Total amount of all tolls paid in trip.'),
    improvement_surcharge NUMERIC OPTIONS (description = '$0.30 improvement surcharge assessed on hailed trips at the flag drop. The improvement surcharge began being levied in 2015.'),
    total_amount NUMERIC OPTIONS (description = 'The total amount charged to passengers. Does not include cash tips.'),
    congestion_surcharge NUMERIC OPTIONS (description = 'Congestion surcharge applied to trips in congested zones')
)
OPTIONS (
    format = 'CSV',
    uris = ['{{ render(vars.gcs_file) }}'],
    skip_leading_rows = 1,
    ignore_unknown_values = TRUE
);
```

Del mismo modo que antes, la consulta de creaci칩n de la tabla la ejecutaremos con una tarea de tipo _consulta de BigQuery_.

```yaml
- id: bq_yellow_table_ext
  type: io.kestra.plugin.gcp.bigquery.Query
  sql: |
    # Creaci칩n de la tabla "externa"
```

##### Asignaci칩n de un identificador y del fichero origen

A continuaci칩n, estableceremos un identificador 칰nico a cada registro y una etiqueta que nos permitir치 m치s adelante saber de qu칠 fichero viene cada dato.

```sql
CREATE OR REPLACE TABLE `{{ kv('GCP_PROJECT_ID') }}.{{ render(vars.table) }}`
AS
SELECT
  MD5(CONCAT(
    COALESCE(CAST(VendorID AS STRING), ""),
    COALESCE(CAST(tpep_pickup_datetime AS STRING), ""),
    COALESCE(CAST(tpep_dropoff_datetime AS STRING), ""),
    COALESCE(CAST(PULocationID AS STRING), ""),
    COALESCE(CAST(DOLocationID AS STRING), "")
  )) AS unique_row_id,
  "{{ render(vars.file) }}" AS filename,
  *
FROM `{{ kv('GCP_PROJECT_ID') }}.{{ render(vars.table) }}_ext`;
```

Una vez m치s, para esto usaremos una tarea de tipo _consulta de BigQuery_.

```yaml
- id: bq_yellow_table_tmp
  type: io.kestra.plugin.gcp.bigquery.Query
  sql: |
    # Asignaci칩n de un identificador y del fichero origen
```

##### Combinaci칩n de los datos con los de la tabla "final"

Como 칰ltimo paso, combinaremos los datos que nos acabamos de descargar con los de la tabla "final".

```sql
MERGE INTO `{{ kv('GCP_PROJECT_ID') }}.{{ kv('GCP_DATASET') }}.yellow_tripdata` T
USING `{{ kv('GCP_PROJECT_ID') }}.{{ render(vars.table) }}` S
ON T.unique_row_id = S.unique_row_id
WHEN NOT MATCHED THEN
  INSERT (unique_row_id, filename, VendorID, tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, RatecodeID, store_and_fwd_flag, PULocationID, DOLocationID, payment_type, fare_amount, extra, mta_tax, tip_amount, tolls_amount, improvement_surcharge, total_amount, congestion_surcharge)
  VALUES (S.unique_row_id, S.filename, S.VendorID, S.tpep_pickup_datetime, S.tpep_dropoff_datetime, S.passenger_count, S.trip_distance, S.RatecodeID, S.store_and_fwd_flag, S.PULocationID, S.DOLocationID, S.payment_type, S.fare_amount, S.extra, S.mta_tax, S.tip_amount, S.tolls_amount, S.improvement_surcharge, S.total_amount, S.congestion_surcharge);
```

Usando nuestra 칰ltima _consulta de BigQuery_ para este dataset.

```yaml
- id: bq_yellow_merge
  type: io.kestra.plugin.gcp.bigquery.Query
  sql: |
    # Merge de los datos descargados con la tabla "final"
```

#### Limpieza de ficheros

Como hicimos en versiones previas del flujo de datos, terminamos asegur치ndonos de borrar los ficheros descargados que ya no necesitamos.

```yaml
- id: purge_files
  type: io.kestra.plugin.core.storage.PurgeCurrentExecutionFiles
  description: If you'd like to explore Kestra outputs, disable it.
  disabled: false
```

## Resultado final

Una vez terminado, nuestro flujo de datos tendr치 un aspecto similar al del fichero [08-gcp-taxi.yaml](resources/flows/08-gcp-taxi.yaml).
